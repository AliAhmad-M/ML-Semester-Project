{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4f62f9c-875c-47ca-97e8-c403f3be8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e941ed-2e53-4241-afe2-f639ef969c5e",
   "metadata": {},
   "source": [
    "## **Training and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90ce6b45-55e7-47b1-8002-731938121950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1172\n",
      "Testing samples: 293\n",
      "Date range: 01/06/2019 to 29/11/2023\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare dataset for SVR\n",
    "df = pd.read_csv('output/data_merged_cleaned.csv')\n",
    "\n",
    "# Convert date and sort chronologically for time-based split\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['aqi_pm2.5', 'date'])\n",
    "y = df['aqi_pm2.5']\n",
    "\n",
    "# Time-based split (80% train, 20% test)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "print(f\"Date range: {df['date'].iloc[0].strftime('%d/%m/%Y')} to {df['date'].iloc[-1].strftime('%d/%m/%Y')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d553035-901d-4ff0-9f9c-db6c5495d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NEAREST NEIGHBORS PERFORMANCE:\n",
      "RMSE: 41.73\n",
      "R² Score: 0.6546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale features for k-NN (distance-based)\n",
    "knn_scaler = StandardScaler()\n",
    "X_train_knn = knn_scaler.fit_transform(X_train)\n",
    "X_test_knn = knn_scaler.transform(X_test)\n",
    "\n",
    "# Train k-NN with default parameters\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train_knn, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = knn_model.predict(X_test_knn)\n",
    "\n",
    "# Evaluate\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_test, y_pred_knn))\n",
    "knn_r2 = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"K-NEAREST NEIGHBORS PERFORMANCE:\")\n",
    "print(f\"RMSE: {knn_rmse:.2f}\")\n",
    "print(f\"R² Score: {knn_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d091b3a-2b60-4a67-928c-10e81217a845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE REGRESSION PERFORMANCE:\n",
      "RMSE: 43.00\n",
      "R² Score: 0.6333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Scale features for Ridge Regression\n",
    "ridge_scaler = StandardScaler()\n",
    "X_train_ridge = ridge_scaler.fit_transform(X_train)\n",
    "X_test_ridge = ridge_scaler.transform(X_test)\n",
    "\n",
    "# Train Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)  # Default regularization\n",
    "ridge_model.fit(X_train_ridge, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ridge = ridge_model.predict(X_test_ridge)\n",
    "\n",
    "# Evaluate\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"RIDGE REGRESSION PERFORMANCE:\")\n",
    "print(f\"RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"R² Score: {ridge_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77254a74-b311-44b2-ab47-776d3bd5b851",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f763434c-2e96-4fca-accb-f2148a06e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUNED K-NEAREST NEIGHBORS:\n",
      "Best Parameters: {'n_neighbors': 20, 'p': 1, 'weights': 'distance'}\n",
      "RMSE: 39.33\n",
      "R² Score: 0.6932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# k-NN parameter grid\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "}\n",
    "\n",
    "# Grid search for k-NN\n",
    "knn_grid = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    knn_param_grid,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn_grid.fit(X_train_knn, y_train)\n",
    "\n",
    "# Best k-NN model\n",
    "best_knn = knn_grid.best_estimator_\n",
    "y_pred_knn_tuned = best_knn.predict(X_test_knn)\n",
    "\n",
    "knn_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred_knn_tuned))\n",
    "knn_tuned_r2 = r2_score(y_test, y_pred_knn_tuned)\n",
    "\n",
    "print(\"TUNED K-NEAREST NEIGHBORS:\")\n",
    "print(f\"Best Parameters: {knn_grid.best_params_}\")\n",
    "print(f\"RMSE: {knn_tuned_rmse:.2f}\")\n",
    "print(f\"R² Score: {knn_tuned_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4bf9ddf-ad8e-475d-8aaf-bad40112d425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUNED RIDGE REGRESSION:\n",
      "Best Parameters: {'alpha': 10, 'solver': 'lsqr'}\n",
      "RMSE: 43.33\n",
      "R² Score: 0.6277\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression parameter grid\n",
    "ridge_param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'saga']\n",
    "}\n",
    "\n",
    "# Grid search for Ridge\n",
    "ridge_grid = GridSearchCV(\n",
    "    Ridge(),\n",
    "    ridge_param_grid,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_grid.fit(X_train_ridge, y_train)\n",
    "\n",
    "# Best Ridge model\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "y_pred_ridge_tuned = best_ridge.predict(X_test_ridge)\n",
    "\n",
    "ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge_tuned))\n",
    "ridge_tuned_r2 = r2_score(y_test, y_pred_ridge_tuned)\n",
    "\n",
    "print(\"TUNED RIDGE REGRESSION:\")\n",
    "print(f\"Best Parameters: {ridge_grid.best_params_}\")\n",
    "print(f\"RMSE: {ridge_tuned_rmse:.2f}\")\n",
    "print(f\"R² Score: {ridge_tuned_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b038089-a39c-48f0-97d3-9a082e91722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN PERFORMANCE BY AQI CATEGORY\n",
      "Category                  Samples    RMSE         Bias        \n",
      "------------------------------------------------------------\n",
      "Good (0-100)              38         51.49        -41.72      \n",
      "Moderate (101-150)        121        22.21        -10.52      \n",
      "Unhealthy (151-200)       70         34.62        -6.74       \n",
      "Very Unhealthy (201-300)  45         35.25        9.24        \n",
      "Hazardous (301-500)       19         89.74        82.62       \n"
     ]
    }
   ],
   "source": [
    "# Ensure required variables exist for SVR category analysis\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define AQI categories\n",
    "aqi_bins = [0, 100, 150, 200, 300, 500]\n",
    "bin_labels = ['Good (0-100)', 'Moderate (101-150)', 'Unhealthy (151-200)', \n",
    "              'Very Unhealthy (201-300)', 'Hazardous (301-500)']\n",
    "\n",
    "# Categorize test samples\n",
    "y_test_binned = pd.cut(y_test, bins=aqi_bins, labels=bin_labels)\n",
    "\n",
    "# Generate k-NN predictions\n",
    "y_pred_knn = best_knn.predict(X_test_knn)\n",
    "\n",
    "# Calculate k-NN performance by category\n",
    "print(\"K-NN PERFORMANCE BY AQI CATEGORY\")\n",
    "print(f\"{'Category':<25} {'Samples':<10} {'RMSE':<12} {'Bias':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "category_results_knn = []\n",
    "for category in bin_labels:\n",
    "    mask = y_test_binned == category\n",
    "    if mask.sum() > 0:\n",
    "        category_rmse = np.sqrt(mean_squared_error(y_test[mask], y_pred_knn[mask]))\n",
    "        category_bias = (y_test[mask] - y_pred_knn[mask]).mean()\n",
    "        \n",
    "        category_results_knn.append({\n",
    "            'category': category,\n",
    "            'samples': mask.sum(),\n",
    "            'rmse': category_rmse,\n",
    "            'bias': category_bias\n",
    "        })\n",
    "        \n",
    "        print(f\"{category:<25} {mask.sum():<10} {category_rmse:<12.2f} {category_bias:<12.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92189c1-bafb-40b8-b597-7c7c31a08e40",
   "metadata": {},
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afdb3fbb-f7eb-4310-a554-ab2d36e803ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced features created: 35 total features\n",
      "\n",
      "Training set: 1172 samples\n",
      "Test set: 293 samples\n",
      "Training dates: 01/06/2019 to 06/01/2023\n",
      "Testing dates: 07/01/2023 to 29/11/2023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_sorted = df.copy()\n",
    "\n",
    "# Base features\n",
    "X_base = df_sorted.drop(columns=['aqi_pm2.5', 'date'])\n",
    "y = df_sorted['aqi_pm2.5']\n",
    "\n",
    "# Create enhanced features\n",
    "X_enhanced = X_base.copy()\n",
    "\n",
    "# Lag features\n",
    "X_enhanced['temp_avg_lag1'] = df_sorted['temp_avg_c'].shift(1)\n",
    "X_enhanced['wind_avg_lag1'] = df_sorted['wind_speed_avg_mph'].shift(1)\n",
    "X_enhanced['humidity_avg_lag1'] = df_sorted['humidity_avg_percent'].shift(1)\n",
    "\n",
    "# Interaction features\n",
    "X_enhanced['wind_temp_interaction'] = X_enhanced['wind_speed_avg_mph'] * X_enhanced['temp_min_c']\n",
    "X_enhanced['wind_humidity_interaction'] = X_enhanced['wind_speed_avg_mph'] * X_enhanced['humidity_avg_percent']\n",
    "\n",
    "# High-risk indicators\n",
    "X_enhanced['high_risk_month'] = X_enhanced['month'].isin([1, 2, 10, 11]).astype(int)\n",
    "X_enhanced['early_winter'] = ((X_enhanced['month'] == 11) | (X_enhanced['month'] == 12)).astype(int)\n",
    "\n",
    "# Rolling features\n",
    "X_enhanced['wind_3day_avg'] = df_sorted['wind_speed_avg_mph'].rolling(3, min_periods=1).mean()\n",
    "X_enhanced['temp_3day_avg'] = df_sorted['temp_avg_c'].rolling(3, min_periods=1).mean()\n",
    "\n",
    "# Fill NaN values\n",
    "X_enhanced = X_enhanced.fillna(X_enhanced.mean())\n",
    "\n",
    "print(f\"Enhanced features created: {X_enhanced.shape[1]} total features\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training dates: {df_sorted['date'].iloc[0].strftime('%d/%m/%Y')} to {df_sorted['date'].iloc[split_idx-1].strftime('%d/%m/%Y')}\")\n",
    "print(f\"Testing dates: {df_sorted['date'].iloc[split_idx].strftime('%d/%m/%Y')} to {df_sorted['date'].iloc[-1].strftime('%d/%m/%Y')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0977ed7-e672-4177-bcfd-cb17f54750eb",
   "metadata": {},
   "source": [
    "## **Final Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbcf808e-a818-4fc3-8ce9-db2b6c81c934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN MODEL PERFORMANCE:\n",
      "RMSE: 38.11\n",
      "R²: 0.7119\n",
      "\n",
      "KNN PERFORMANCE BY AQI CATEGORY:\n",
      "Category                  Samples    RMSE         Bias        \n",
      "------------------------------------------------------------\n",
      "Good (0-100)              38         47.67        -37.58      \n",
      "Moderate (101-150)        121        21.78        -7.52       \n",
      "Unhealthy (151-200)       70         35.49        -3.48       \n",
      "Very Unhealthy (201-300)  45         43.21        3.34        \n",
      "Hazardous (301-500)       19         75.96        61.28       \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Initialize KNN with optimized parameters\n",
    "knn_model = KNeighborsRegressor(\n",
    "    n_neighbors=7,          \n",
    "    weights='distance',     \n",
    "    p=1,                    \n",
    "    n_jobs=-1               \n",
    ")\n",
    "\n",
    "# Train KNN\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate KNN\n",
    "rmse_knn = root_mean_squared_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nKNN MODEL PERFORMANCE:\")\n",
    "print(f\"RMSE: {rmse_knn:.2f}\")\n",
    "print(f\"R²: {r2_knn:.4f}\")\n",
    "\n",
    "# Category performance analysis\n",
    "print(\"\\nKNN PERFORMANCE BY AQI CATEGORY:\")\n",
    "\n",
    "aqi_bins = [0, 100, 150, 200, 300, 500]\n",
    "bin_labels = ['Good (0-100)', 'Moderate (101-150)', 'Unhealthy (151-200)', \n",
    "              'Very Unhealthy (201-300)', 'Hazardous (301-500)']\n",
    "\n",
    "y_test_binned = pd.cut(y_test, bins=aqi_bins, labels=bin_labels)\n",
    "\n",
    "print(f\"{'Category':<25} {'Samples':<10} {'RMSE':<12} {'Bias':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for category in bin_labels:\n",
    "    mask = y_test_binned == category\n",
    "    if mask.sum() > 0:\n",
    "        category_rmse = root_mean_squared_error(y_test[mask], y_pred_knn[mask])\n",
    "        category_bias = (y_test[mask] - y_pred_knn[mask]).mean()\n",
    "        print(f\"{category:<25} {mask.sum():<10} {category_rmse:<12.2f} {category_bias:<12.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8d4f736-741b-4cfb-a984-246a439e2c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPARISON WITH XGBOOST:\n",
      "KNN RMSE: 38.11 vs XGBoost RMSE: 33.69\n",
      "\n",
      "KNN Hazardous Days RMSE: 75.96\n",
      "XGBoost Hazardous RMSE: 57.83\n",
      "Difference: 18.13 RMSE points\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare with XGBoost\n",
    "print(\"\\nCOMPARISON WITH XGBOOST:\")\n",
    "print(f\"KNN RMSE: {rmse_knn:.2f} vs XGBoost RMSE: 33.69\")\n",
    "\n",
    "# Hazardous days specific analysis\n",
    "hazardous_mask = y_test > 300\n",
    "if hazardous_mask.sum() > 0:\n",
    "    knn_hazardous_rmse = root_mean_squared_error(y_test[hazardous_mask], y_pred_knn[hazardous_mask])\n",
    "    print(f\"\\nKNN Hazardous Days RMSE: {knn_hazardous_rmse:.2f}\")\n",
    "    print(f\"XGBoost Hazardous RMSE: 57.83\")\n",
    "    print(f\"Difference: {knn_hazardous_rmse - 57.83:.2f} RMSE points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32d44e52-9d8a-4a70-80b9-13e76dc046aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN model saved to output/models/knn_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Save k-NN model and scaler\n",
    "knn_model_data = {\n",
    "    'model': knn_model,\n",
    "    'scaler': scaler_X,\n",
    "    'feature_names': X_train.columns.tolist()\n",
    "}\n",
    "\n",
    "joblib.dump(knn_model_data, 'output/models/knn_model.pkl')\n",
    "print(\"k-NN model saved to output/models/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facefc0-64e4-49cd-94eb-f233313be06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
